

\chapter{Aplicação do Procedimento}

Neste capítulo o procedimento será ilustrado em um modelo de regressão de preços de imóveis. Os dados foram adquiridas via \textit{webscrapping} de um site nacional de aluguel de imóveis para 4 capitais brasileiras no dia 20 de Março de 2020, realizado pelo autor. Iremos estimar uma série de modelos com variadas configurações de hiperparametros e computar algumas métricas de sucesso para explorar como eles afetam performance do modelo. Essas métricas de sucesso serão computadas com dados omitidos no processo de treinamento, num processo chamado Validação Cruzada, e então aplicaremos o procedimento descrito no capítulo anterior.

\section{Otimização de Hiperparametros}

Não existe uma única maneira de estimar uma floresta aleatória. De fato, como machine learning é um campo que cresceu muito às margens da academia, em laboratórios da indústria, as convenções são informais e há pouco escrito em pedra. Optei por usar a implementação em \citeonline{ranger}, que usa como gatilho de geração de folhas uma amostra abaixo da mínima chegar no nodo e aleatoriza quantas variáveis explicativas são usadas em cada árvore. Uma alternativa de alta confiabilidade seria \citeonline{randomForest}. Para a otimização de hiperparametros, validação cruzada e avaliação dos modelos foi usada a plataforma \texttt{tidymodels} \cite{tidymodels}, implementada em linguagem R \cite{R}.

Decidida a implementação que irá realizar as computações, é preciso fazer uma escolha sobre os hiperparâmetros do modelo, no caso três: amostra mínima para criação de folha, número de árvores e número de variáveis a serem aleatoriamente escolhidas para cada árvore. Do ponto de vista do expectador desinteressado o problema é apenas:

\begin{align}
    \mathbf{x}^* = \underset{\mathbf{x}}{\text{arg max}} \,\,\phi(\mathbf{x}) 
\end{align}

E como seria fácil se soubéssemos exatamente o que é $\phi(\cdot)$, mas não sabemos. Uma primeira abordagem é tatear o suporte da função em busca da melhor combinação. Um método para isso é \textit{random search}, gerar algumas combinações de hiperparâmetros aleatórias, estimar um modelo em cada e escolher o de melhor performance, que definiremos em detalhes brevemente. O dual dessa abordagem é \textit{grid search} em que ao invés de gerar combinações aleatórias se cobre o espaço de hiperparâmetros de vetores com distância regular, gerando uma grade. 

Essas são ditas abordagens \textbf{caixa-preta livre de modelo} pois não fazem suposições sobre a forma funcional da função a ser maximizada ajustando os hiperparâmetros. Varremos o que acreditamos ser o seu domínio à força bruta. Existem alternativas, \citeonline{shahriari2015taking} é um tratamento amplo da principal, otimização bayesiana. Otimização de Hiperparâmetros é um campo vasto. Um tratamento mais detalhado do estado da arte na área está disponível em \citeonline{feurer2019hyperparameter}.


\begin{figure}[H]
    \centering
    \includegraphics[scale = .75]{imagens/random_grid.png}
    \caption{Duas buscas de 100 modelos cada. Elaboração própria.}
\end{figure}

\section{Métricas de Qualidade}

Na seção anterior optamos por escolher hiperparâmetros de forma a maximizar alguma função que entendemos representar a qualidade de um modelo. Precisamos agora definir como mensura-la. Métricas de performance de modelo são sempre arbitrárias então a boa prática recomenda usar uma cesta delas. As opções para regressão são inúmeras. Serão avaliadas seis:

\begin{itemize}
    \item \textbf{Razão Performance-Interquatil (RPIQ)} \newline
    Definida como o desvio-padrão das previsões dividido pela amplitude interquartil da resposta. Mede principalmente a consistência do modelo, não a acurácia preditiva. Quanto mais próximo de 1, melhor. 
    
    \item \textbf{Coeficiente de Concordância de Correlação (CCC)} \newline
    Introduzido por \citeonline{lawrence1989concordance}, mede tanto consistência quanto acurácia. Calculada a partir da diferença entre a identidade e a reta de regressão dos valores preditos nos verdadeiros. Quanto mais próximo de 1, melhor.
    
    \item \textbf{Erro Médio Absoluto (MAE)} \newline
    A média das diferenças entre previsões e valores verdadeiros. Diretamente interpretável na unidade original da resposta. Indica acurácia. Menor é melhor, mas deve-se atentar à parcimônia.
    
    \item \textbf{Erro Médio Percentual (MPE)} \newline
    A média das diferenças entre previsões e valores verdadeiros ponderada pela média da resposta. Lida em unidades relativas. Indica acurácia. Menor é melhor, mas deve-se atentar à parcimônia.
    
    \item \textbf{Coeficiente de Determinação (R2)} \newline
    Calcula-se a soma dos quadrados dos desvios das previsões à média da resposta. Dividi-se esse valor pela soma dos quadrados dos desvios as observações originais à média da resposta. O resultado está entre $0$ e $1$ e pode ser interpretado como a fração da variância que o modelo consegue explicar. Mede principalmente consistência, não acurácia. Maior é melhor, mas deve-se atentar à parcimônia pois cresce monotonamente no número de variáveis explicativas.
    
    \item \textbf{Raiz do Erro Quadrático Médio (RMSE)} \newline
    O Erro Quadrático Médio é a média dos quadrados dos desvios das previsões em relação aos valores verdadeiros. A raiz dá a métrica. Mede principalmente acurácia, embora seja muito sensível a outliers. Menor é melhor.
    
\end{itemize}

Em um contexto de classificação precisamos de outras métricas. A título de exemplo, algumas das mais amplamente utilizadas são:

\begin{itemize}
    \item \textbf{Sensitividade/ Recall} \newline
    Em classificação binária, a Sensitividade é a proporção dos casos positivos que são corretamente identificados.
    \item \textbf{Especificidade} \newline
    Em classificação binária, a Especificidade é a proporção dos casos negativos que são corretamente identificados.
    \item \textbf{Acurácia} \newline
    A fração de casos corretamente identificados. 
    \item \textbf{Precisão/ Valor Preditivo Positivo} \newline
    O número de verdadeiros positivos dividido pelo número de preditos positivos.
    \item \textbf{F1-Score} \newline
    Média harmônia da Precisão e da Sensitividade
\end{itemize}


\section{Validação Cruzada}

Para dar uma chance melhor a cada combinação podemos testa-la em amostras diferentes. Fazemos isso com validação $k$-cruzada. Dividimos a amostra em $k$ grupos aproximadamente iguais e para cada combinação de hiperparâmetros estimamos o modelo em $k-1$ combinações, excluindo um grupo de cada vez. Como medida de performance para cada combinação específica de hiperparâmetros usamos então a média das métricas de performance nas $k-1$ validações. 

Um pouco de sabedoria popular com florestas aleatórias sugere que o número de árvores não é um bom hiperparâmetro para se validar. Os ganhos de performance são pequenos, o custo computacional, no entanto, variante. Note que o custo de estimar uma floresta cresce linearmente, um para um, com o número de árvores. Validar $k$ combinações cada uma com $a*b$ árvores é $a$ vezes mais caro que validar $k$ combinações com $b$ árvores. 

Esse tempo de computação é melhor empregado procurando com uma grade fina melhores combinações de amostra única e número de variáveis por árvore. Árvores com menos variáveis tem menos variância, o que ajuda a diminuir a variância da floresta, e menor poder preditivo. Árvores com menor amostra mínima têm mais folhas, criando respostas mais finas, mas têm mais variância também. 


\begin{figure}[H]
    \centering
    \includegraphics[scale = .72]{imagens/cross_v_mtry.png}
    \caption{Resumo de métricas de performance variando quantas variáveis alimentar para cada árvore. Elaboração própria.}
\end{figure}

A varredura pelo hiperparâmetro do número de variáveis sugere que ele não é muito determinante para performance. Não há movimento claros entre as métricas de melhora ou piora. Poucas variáveis por árvore incluem tanto os melhores quanto os piores modelos! O que sugere que a amostra mínima para gerar folha é um hiperparâmetro mais relevante. De fato é:


\begin{figure}[H]
    \centering
    \includegraphics[scale = .70]{imagens/crossv_min.png}
    \caption{Resumo de métricas de performance variando a amostra mínima para criar uma folha. Elaboração própria.}
\end{figure}

\input{tabelas/hiper_metricas}



\section{Computação de Efeitos Marginais}

Ao aplicar o procedimento com um modelo linear, o que temos? Justamente o que modelos lineares deveriam devolver na ausência de termos com interações e funções não-lineares dos regressores originais, efeitos marginais constantes:

\begin{figure}[H]
    \centering
    \includegraphics[scale = .70]{imagens/efeitos_marginais_lm.png}
    \caption{A aplicação do procedimento em modelos lineares ilustra a primeira hipótese dos modelos. Elaboração própria.}
\end{figure}

Já em modelos de floresta aleatória a não-linearidade do fenômeno fica evidente. Sair do térreo para o primeiro andar \textit{barateia} um apartamento, presumivelmente porque o benefício de uma vista é quase inexistente embora o custo de subir escada/elevador apareça. Sair do décimo segundo para o décimo terceiro tem um efeito nulo e por vezes negativo. Possivelmente por conta da superstição com o número.

Esse tipo de efeito poderia ser aproximado com regressões quantílicas, estando o quão finamente o suporte da variável explicativa pode ser mapeado limitado pelo tamanho da amostra. Mais quantis implicam em amostras sucessivamente menores. Essa limitação não está presente em florestas aleatórias. 

Outra diferença é que modelos lineares são \textit{globais}. Os efeitos marginais independem dos níveis de outros regressores então o salto do térreo para o primeiro andar seria tido como igual para todo apartamento, em toda cidade, de qualquer tamanho. Esse tipo de nuance não é perdida em modelos de florestas aleatórias. 

\begin{figure}[H]
    \centering
    \includegraphics[scale = .70]{imagens/efeitos_marginais_RF.png}
    \caption{Em florestas aleatórias a heterogeneidade dos efeitos de tratamento fica evidente. Elaboração própria.}
\end{figure}

Os dados com as previsões médias para cada nível de regressor podem ser interpolados e assim gerar uma curva de efeitos marginais. É possível considerar interações entre regressores ao iterar o processo em regressores diferentes e construir funções multivariadas de efeitos marginais. A noção não é tão clara em um caso de classificação, mas é possível estende-la. 

Afinal, cada árvore na floresta dá um voto contendo a sua classificação predita. A classe mais votada é dada como classe predita pela floresta. Podemos ler a fração dos votos que a classe mais votada levou como uma probabilidade predita e calcular os efeitos marginais da mesma maneira que faríamos em um caso de regressão, avaliando o efeito sobre a probabilidade predita. Essa mudança para que a saída do modelo seja em termos de probabilidade é trivial na maioria das implementações computacionais destes métodos e não leva a um aumento de complexidade da tarefa.










